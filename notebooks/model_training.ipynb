{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330beb7e-c5af-4236-9e19-1510727b2683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tpot import TPOTRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the preprocessed training data\n",
    "train_data = pd.read_csv('../data/Processed/processed_train_data.csv').copy()\n",
    "\n",
    "# 1. Select numerical features\n",
    "# Select numerical columns and separate features (X) and target (y).\n",
    "X = train_data.select_dtypes(include=['float64', 'int64']).drop(columns=['SalePrice'])\n",
    "y = train_data['SalePrice']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# 80-20 split for training and testing data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Create and train the model\n",
    "# Instantiate and train the RandomForestRegressor model.\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Calculate SHAP values\n",
    "# Use SHAP to calculate the contribution of each feature to the model’s prediction.\n",
    "explainer = shap.TreeExplainer(rf_model)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# 4. Visualize SHAP values\n",
    "# Visualize the impact of features on predictions using SHAP summary plot.\n",
    "shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651acf2a-6f03-42a0-b9bb-663e478c1c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top 25 features\n",
    "# This list contains the 25 features with the most influence on the target variable.\n",
    "top_25_features = [\n",
    "    'Overall_Quality_Impact', 'Overall_Quality', 'Neighborhood_avg_price', 'TotalBsmtSF',\n",
    "    'BsmtQual_to_BsmtFinSF', 'TotalOutdoorArea', 'OverallQual', '2ndFlrSF', '1stFlrSF', \n",
    "    'BsmtFinSF1', 'YearBuilt', 'LotArea', 'Garage_Capacity_per_Square_Meter', \n",
    "    'FireplaceQu_OverallQuality_Interaction', 'GrLivArea', 'GarageCars', 'OpenPorchSF', \n",
    "    'PavedDrive_LotFrontage_Interaction', 'BsmtUnfSF', 'YearRemodAdd', 'BsmtFinSF_to_TotalArea',\n",
    "    'Garage_Feature', 'GarageYrBlt', 'LotFrontage', 'Functional_OverallQuality_Interaction'\n",
    "]\n",
    "\n",
    "# Filter the data to keep only the selected features\n",
    "# Create new datasets with the top 25 features for training and testing.\n",
    "X_train_25 = X_train[top_25_features]\n",
    "X_test_25 = X_test[top_25_features]\n",
    "\n",
    "# Retrain the model using RandomForestRegressor\n",
    "# Train the model on the filtered dataset (X_train_25).\n",
    "rf_model_25 = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model_25.fit(X_train_25, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "# Predict the target values using the trained model and test data.\n",
    "y_pred_25 = rf_model_25.predict(X_test_25)\n",
    "\n",
    "# Calculate performance metrics\n",
    "# Calculate MSE, RMSE, and MAE to evaluate the model's performance.\n",
    "mse_25 = mean_squared_error(y_test, y_pred_25)\n",
    "rmse_25 = np.sqrt(mse_25)\n",
    "mae_25 = mean_absolute_error(y_test, y_pred_25)\n",
    "\n",
    "# Print the results\n",
    "# Display the calculated metrics.\n",
    "print(f\"Mean Squared Error (MSE): {mse_25}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_25}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_25}\")\n",
    "\n",
    "# Show feature importance scores\n",
    "# Retrieve and display the importance of each feature based on the trained model.\n",
    "importances_25 = rf_model_25.feature_importances_\n",
    "importances_25_df = pd.DataFrame({\n",
    "    'Feature': top_25_features,\n",
    "    'Importance': importances_25\n",
    "})\n",
    "\n",
    "# Sort the features by importance\n",
    "# Sort the features to identify the most important ones.\n",
    "importances_25_sorted = importances_25_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 25 Important Features:\\n\", importances_25_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a847304-b3a8-4c36-af3c-6652b1e8dc22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select top 20 features for training\n",
    "top_20_features = [\n",
    "    'Overall_Quality_Impact', 'Overall_Quality', 'Neighborhood_avg_price', 'TotalBsmtSF',\n",
    "    'BsmtQual_to_BsmtFinSF', 'TotalOutdoorArea', 'OverallQual', '2ndFlrSF', '1stFlrSF', \n",
    "    'BsmtFinSF1', 'YearBuilt', 'LotArea', 'Garage_Capacity_per_Square_Meter', \n",
    "    'FireplaceQu_OverallQuality_Interaction', 'GrLivArea', 'GarageCars', 'OpenPorchSF', \n",
    "    'PavedDrive_LotFrontage_Interaction', 'BsmtUnfSF', 'YearRemodAdd', 'BsmtFinSF_to_TotalArea'\n",
    "]\n",
    "\n",
    "# Load and split data\n",
    "X = train_data[top_20_features]  # Input features\n",
    "y = train_data['SalePrice']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # Split into training and test sets\n",
    "\n",
    "# TPOTRegressor setup for automatic model optimization\n",
    "tpot = TPOTRegressor(\n",
    "    generations=20, \n",
    "    population_size=100, \n",
    "    random_state=42,\n",
    "    max_time_mins=180,  # Run for 3 hours max\n",
    "    max_eval_time_mins=20,  # Each model evaluation lasts 20 minutes\n",
    "    n_jobs=-1,  # Use all processor cores\n",
    "    verbosity=3,  # Detailed output\n",
    "    crossover_rate=0.95,  # High crossover rate\n",
    "    mutation_rate=0.05,  # Low mutation rate\n",
    "    subsample=0.9,  # Use 90% of the data\n",
    "    early_stop=10  # Stop after 10 generations without improvement\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = tpot.predict(X_test)\n",
    "\n",
    "# Evaluate model performance using MSE, RMSE, and MAE\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5  # RMSE is the square root of MSE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "# Print the best pipeline found by TPOT\n",
    "print(tpot.fitted_pipeline_)\n",
    "\n",
    "# Save the best model\n",
    "import joblib\n",
    "model_path = \"../models/stacked_extra_trees_regressor_model.pkl\"\n",
    "joblib.dump(tpot.fitted_pipeline_, model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72d2ee3-8534-42d6-8937-8783fd904263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "# We are loading the previously trained and saved model using `joblib.load()`. This lets us reuse the model \n",
    "# for predictions without retraining it from scratch.\n",
    "model = joblib.load('../models/stacked_extra_trees_regressor_model.pkl')\n",
    "\n",
    "# Load the processed training data\n",
    "# Here, we load the data from 'processed_train_data.csv' which contains the features and target variable.\n",
    "# The `copy()` method ensures that we are working with a copy of the data, preserving the original data intact.\n",
    "train_data = pd.read_csv('../data/Processed/processed_train_data.csv').copy()\n",
    "\n",
    "# Select features and target variable\n",
    "# We are selecting the most important features (`top_20_features`) and the target variable (`SalePrice`) for training.\n",
    "X = train_data[top_20_features]  # Input features\n",
    "y = train_data['SalePrice']  # Target variable to predict\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# We split the data into 80% training data and 20% testing data using `train_test_split()`.\n",
    "# This ensures that the model is trained on one part of the data and evaluated on another, helping to avoid overfitting.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "# We train the loaded model on the training data (X_train and y_train) to learn the relationship between features and the target.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "# After training, we use the model to make predictions on the test data (X_test).\n",
    "# These predictions are compared with actual values (y_test) to evaluate performance.\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the R² score\n",
    "# R² (R-squared) indicates how well the model explains the variance in the target variable.\n",
    "# A higher R² score means the model fits the data better.\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the R² score\n",
    "# We print the R² score to evaluate how well the model performs on unseen test data.\n",
    "print(f\"R² Score: {r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
