{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15de4d46-9523-4872-b0d7-e9f06d1c398e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "processed_train_data = pd.read_csv('../data/processed/processed_train_data.csv').copy()\n",
    "processed_train_data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "processed_train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5381f4-ec86-42cb-806d-e0fc9052a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b06b141-1fab-4c52-8595-6948b796fb01",
   "metadata": {},
   "source": [
    "## Model 1: XGBoost Model with Standard Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0edd31-a139-4a94-b1f4-b8852ea463c5",
   "metadata": {},
   "source": [
    "### Steps to Prevent Data Leakage in the Neighborhood Variable\n",
    "##### For each fold, the neighborhood statistics are calculated only using the training data. Smoothed average prices for each neighborhood are computed by combining the neighborhood mean with the global training mean to reduce noise from small samples. These smoothed values are then mapped to both training and validation sets. Unknown neighborhoods in validation get the global mean. This process ensures no target information from validation leaks into training. Finally, the original neighborhood column is removed, leaving only the numerical smoothed feature for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bb7d5d-f940-494c-a118-17502f8667ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import zscore\n",
    "\n",
    "X = processed_train_data.drop(columns=['SalePrice'])\n",
    "y = np.log1p(processed_train_data['SalePrice'])  # Log-transform target\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "mse_list, rmse_list, mae_list, r2_list = [], [], [], []\n",
    "fold = 1\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index].copy(), X.iloc[val_index].copy()\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # Filter outliers in training set using Z-score\n",
    "    y_train_prices = np.expm1(y_train)\n",
    "    z_scores = zscore(y_train_prices)\n",
    "    mask = (z_scores > -3) & (z_scores < 3)\n",
    "\n",
    "    X_train_filtered = X_train[mask].copy()\n",
    "    y_train_filtered = y_train[mask]\n",
    "\n",
    "    # Smoothing mean encoding for Neighborhood\n",
    "    temp_df = X_train_filtered.copy()\n",
    "    temp_df['SalePrice'] = y_train_filtered\n",
    "\n",
    "    neighborhood_stats = temp_df.groupby('Neighborhood')['SalePrice'].agg(['mean', 'count'])\n",
    "    global_mean = y_train_filtered.mean()\n",
    "\n",
    "    alpha = 10  # smoothing parameter\n",
    "    neighborhood_stats['smoothed'] = (\n",
    "        neighborhood_stats['mean'] * neighborhood_stats['count'] + global_mean * alpha\n",
    "    ) / (neighborhood_stats['count'] + alpha)\n",
    "\n",
    "    X_train['Neighborhood_avg_price'] = X_train['Neighborhood'].map(neighborhood_stats['smoothed'])\n",
    "    X_val['Neighborhood_avg_price'] = X_val['Neighborhood'].map(neighborhood_stats['smoothed'])\n",
    "\n",
    "    # Fill missing values with global mean\n",
    "    X_train['Neighborhood_avg_price'].fillna(global_mean, inplace=True)\n",
    "    X_val['Neighborhood_avg_price'].fillna(global_mean, inplace=True)\n",
    "\n",
    "    X_train.drop(columns=['Neighborhood'], inplace=True)\n",
    "    X_val.drop(columns=['Neighborhood'], inplace=True)\n",
    "\n",
    "    # Model definition and training\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and inverse transform\n",
    "    y_pred_log = model.predict(X_val)\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    y_val_orig = np.expm1(y_val)\n",
    "\n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_val_orig, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_val_orig, y_pred)\n",
    "    r2 = r2_score(y_val_orig, y_pred)\n",
    "\n",
    "    print(f\"Fold {fold} -> MSE: {mse:.2f}, RMSE: {rmse:.2f}, MAE: {mae:.2f}, R2: {r2:.4f}\")\n",
    "\n",
    "    mse_list.append(mse)\n",
    "    rmse_list.append(rmse)\n",
    "    mae_list.append(mae)\n",
    "    r2_list.append(r2)\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "print(\"\\n--- 10-Fold CV Average Results ---\")\n",
    "print(f\"Average MSE: {np.mean(mse_list):.2f}\")\n",
    "print(f\"Average RMSE: {np.mean(rmse_list):.2f}\")\n",
    "print(f\"Average MAE: {np.mean(mae_list):.2f}\")\n",
    "print(f\"Average R2: {np.mean(r2_list):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b27ce7-ec8c-48ca-8fb0-c18f4483da34",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning Using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66a5d5f-632a-498e-bcc8-bff566725f3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1500),\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "            'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
    "            'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
    "            'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),\n",
    "            'random_state': 42,\n",
    "            'verbosity': 0\n",
    "        }\n",
    "    \n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        rmse_scores = []\n",
    "    \n",
    "        for train_idx, val_idx in kf.split(X):\n",
    "            X_train, X_val = X.iloc[train_index].copy(), X.iloc[val_index].copy()\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        \n",
    "            # Filter outliers in training set using Z-score\n",
    "            y_train_prices = np.expm1(y_train)\n",
    "            z_scores = zscore(y_train_prices)\n",
    "            mask = (z_scores > -3) & (z_scores < 3)\n",
    "        \n",
    "            X_train_filtered = X_train[mask].copy()\n",
    "            y_train_filtered = y_train[mask]\n",
    "        \n",
    "            # Smoothing mean encoding for Neighborhood\n",
    "            temp_df = X_train_filtered.copy()\n",
    "            temp_df['SalePrice'] = y_train_filtered\n",
    "        \n",
    "            neighborhood_stats = temp_df.groupby('Neighborhood')['SalePrice'].agg(['mean', 'count'])\n",
    "            global_mean = y_train_filtered.mean()\n",
    "        \n",
    "            alpha = 10  # smoothing parameter\n",
    "            neighborhood_stats['smoothed'] = (\n",
    "                neighborhood_stats['mean'] * neighborhood_stats['count'] + global_mean * alpha\n",
    "            ) / (neighborhood_stats['count'] + alpha)\n",
    "        \n",
    "            X_train['Neighborhood_avg_price'] = X_train['Neighborhood'].map(neighborhood_stats['smoothed'])\n",
    "            X_val['Neighborhood_avg_price'] = X_val['Neighborhood'].map(neighborhood_stats['smoothed'])\n",
    "        \n",
    "            # Fill missing values with global mean\n",
    "            X_train['Neighborhood_avg_price'].fillna(global_mean, inplace=True)\n",
    "            X_val['Neighborhood_avg_price'].fillna(global_mean, inplace=True)\n",
    "        \n",
    "            X_train.drop(columns=['Neighborhood'], inplace=True)\n",
    "            X_val.drop(columns=['Neighborhood'], inplace=True)\n",
    "    \n",
    "            model = XGBRegressor(**params)\n",
    "            model.fit(X_train, y_train)\n",
    "    \n",
    "            y_pred_log = model.predict(X_val)\n",
    "            y_pred = np.expm1(y_pred_log)\n",
    "            y_val_orig = np.expm1(y_val)\n",
    "    \n",
    "            rmse = np.sqrt(mean_squared_error(y_val_orig, y_pred))\n",
    "            rmse_scores.append(rmse)\n",
    "    \n",
    "            return np.mean(rmse_scores)\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  RMSE: {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71171cbd-3ae7-4096-8897-a52ad02e87a9",
   "metadata": {},
   "source": [
    "## Model 2: Fine Tuned XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53ec938-48b1-4957-be93-7abe0055b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import zscore\n",
    "\n",
    "X = processed_train_data.drop(columns=['SalePrice'])\n",
    "y = np.log1p(processed_train_data['SalePrice'])  # Log-transform target\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "mse_list, rmse_list, mae_list, r2_list = [], [], [], []\n",
    "fold = 1\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index].copy(), X.iloc[val_index].copy()\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # Filter outliers in training set using Z-score\n",
    "    y_train_prices = np.expm1(y_train)\n",
    "    z_scores = zscore(y_train_prices)\n",
    "    mask = (z_scores > -3) & (z_scores < 3)\n",
    "\n",
    "    X_train_filtered = X_train[mask].copy()\n",
    "    y_train_filtered = y_train[mask]\n",
    "\n",
    "    # Smoothing mean encoding for Neighborhood\n",
    "    temp_df = X_train_filtered.copy()\n",
    "    temp_df['SalePrice'] = y_train_filtered\n",
    "\n",
    "    neighborhood_stats = temp_df.groupby('Neighborhood')['SalePrice'].agg(['mean', 'count'])\n",
    "    global_mean = y_train_filtered.mean()\n",
    "\n",
    "    alpha = 10  # smoothing parameter\n",
    "    neighborhood_stats['smoothed'] = (\n",
    "        neighborhood_stats['mean'] * neighborhood_stats['count'] + global_mean * alpha\n",
    "    ) / (neighborhood_stats['count'] + alpha)\n",
    "\n",
    "    X_train['Neighborhood_avg_price'] = X_train['Neighborhood'].map(neighborhood_stats['smoothed'])\n",
    "    X_val['Neighborhood_avg_price'] = X_val['Neighborhood'].map(neighborhood_stats['smoothed'])\n",
    "\n",
    "    # Fill missing values with global mean\n",
    "    X_train['Neighborhood_avg_price'].fillna(global_mean, inplace=True)\n",
    "    X_val['Neighborhood_avg_price'].fillna(global_mean, inplace=True)\n",
    "\n",
    "    X_train.drop(columns=['Neighborhood'], inplace=True)\n",
    "    X_val.drop(columns=['Neighborhood'], inplace=True)\n",
    "\n",
    "    # Model definition and training\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=1248,\n",
    "        learning_rate=0.05499096292974256,\n",
    "        max_depth=4,\n",
    "        subsample=0.577013993087534,\n",
    "        colsample_bytree=0.9068997064085227,\n",
    "        gamma=0.0004916084930462287,\n",
    "        reg_alpha=1.0951310305247596e-05,\n",
    "        reg_lambda=0.03878934490687091,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and inverse transform\n",
    "    y_pred_log = model.predict(X_val)\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    y_val_orig = np.expm1(y_val)\n",
    "\n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_val_orig, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_val_orig, y_pred)\n",
    "    r2 = r2_score(y_val_orig, y_pred)\n",
    "\n",
    "    print(f\"Fold {fold} -> MSE: {mse:.2f}, RMSE: {rmse:.2f}, MAE: {mae:.2f}, R2: {r2:.4f}\")\n",
    "\n",
    "    mse_list.append(mse)\n",
    "    rmse_list.append(rmse)\n",
    "    mae_list.append(mae)\n",
    "    r2_list.append(r2)\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "print(\"\\n--- 10-Fold CV Average Results ---\")\n",
    "print(f\"Average MSE: {np.mean(mse_list):.2f}\")\n",
    "print(f\"Average RMSE: {np.mean(rmse_list):.2f}\")\n",
    "print(f\"Average MAE: {np.mean(mae_list):.2f}\")\n",
    "print(f\"Average R2: {np.mean(r2_list):.4f}\")\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(model, '../models/xgb_model_final.joblib')\n",
    "print(\"Final model successfully saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a788f-81c1-47c3-acac-2bdec639d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_model = joblib.load('../models/xgb_model_final.joblib')\n",
    "print(XGB_model.feature_names_in_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bed2a0c-ed8f-42b6-ab57-e8ebcc069a6e",
   "metadata": {},
   "source": [
    "## Model 3: TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1fd903-939a-4b5d-9e42-0b9e9845c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import zscore\n",
    "from tpot import TPOTRegressor\n",
    "import joblib\n",
    "\n",
    "# Assume processed_train_data is already loaded and preprocessed\n",
    "X = processed_train_data.drop(columns=['SalePrice'])\n",
    "y = np.log1p(processed_train_data['SalePrice'])  # Log-transform target\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "mse_list, rmse_list, mae_list, r2_list = [], [], [], []\n",
    "fold = 1\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index].copy(), X.iloc[val_index].copy()\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # Outlier removal in training target using Z-score\n",
    "    y_train_prices = np.expm1(y_train)\n",
    "    z_scores = zscore(y_train_prices)\n",
    "    mask = (z_scores > -3) & (z_scores < 3)\n",
    "    X_train_filtered = X_train[mask].copy()\n",
    "    y_train_filtered = y_train[mask]\n",
    "\n",
    "    # Smoothing mean encoding for 'Neighborhood'\n",
    "    temp_df = X_train_filtered.copy()\n",
    "    temp_df['SalePrice'] = y_train_filtered\n",
    "    neighborhood_stats = temp_df.groupby('Neighborhood')['SalePrice'].agg(['mean', 'count'])\n",
    "    global_mean = y_train_filtered.mean()\n",
    "    alpha = 10  # smoothing parameter\n",
    "\n",
    "    neighborhood_stats['smoothed'] = (\n",
    "        neighborhood_stats['mean'] * neighborhood_stats['count'] + global_mean * alpha\n",
    "    ) / (neighborhood_stats['count'] + alpha)\n",
    "\n",
    "    X_train['Neighborhood_avg_price'] = X_train['Neighborhood'].map(neighborhood_stats['smoothed'])\n",
    "    X_val['Neighborhood_avg_price'] = X_val['Neighborhood'].map(neighborhood_stats['smoothed'])\n",
    "    X_train['Neighborhood_avg_price'].fillna(global_mean, inplace=True)\n",
    "    X_val['Neighborhood_avg_price'].fillna(global_mean, inplace=True)\n",
    "\n",
    "    X_train.drop(columns=['Neighborhood'], inplace=True)\n",
    "    X_val.drop(columns=['Neighborhood'], inplace=True)\n",
    "\n",
    "    # TPOTRegressor - AutoML with genetic programming\n",
    "    tpot = TPOTRegressor(\n",
    "        generations=10,          # Number of iterations to evolve pipelines\n",
    "        population_size=50,      # Number of pipelines per generation\n",
    "        verbosity=2,             # Show progress logs\n",
    "        scoring='neg_mean_squared_error',  # Optimize for MSE\n",
    "        random_state=42,\n",
    "        n_jobs=-1,               # Use all CPU cores\n",
    "        max_time_mins=30         # Max time in minutes per fold\n",
    "    )\n",
    "\n",
    "    tpot.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on validation set and inverse log-transform\n",
    "    y_pred_log = tpot.predict(X_val)\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    y_val_orig = np.expm1(y_val)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    mse = mean_squared_error(y_val_orig, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_val_orig, y_pred)\n",
    "    r2 = r2_score(y_val_orig, y_pred)\n",
    "\n",
    "    print(f\"Fold {fold} -> MSE: {mse:.2f}, RMSE: {rmse:.2f}, MAE: {mae:.2f}, R2: {r2:.4f}\")\n",
    "\n",
    "    mse_list.append(mse)\n",
    "    rmse_list.append(rmse)\n",
    "    mae_list.append(mae)\n",
    "    r2_list.append(r2)\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "print(\"\\n--- 10-Fold CV Average Results ---\")\n",
    "print(f\"Average MSE: {np.mean(mse_list):.2f}\")\n",
    "print(f\"Average RMSE: {np.mean(rmse_list):.2f}\")\n",
    "print(f\"Average MAE: {np.mean(mae_list):.2f}\")\n",
    "print(f\"Average R2: {np.mean(r2_list):.4f}\")\n",
    "\n",
    "# Save the best pipeline found by TPOT from last fold\n",
    "joblib.dump(tpot.fitted_pipeline_, '../models/tpot_model_final.joblib')\n",
    "print(\"Final TPOT model successfully saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
